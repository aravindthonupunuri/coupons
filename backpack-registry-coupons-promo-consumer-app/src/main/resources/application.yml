micronaut:
  application:
    name: backpack-registry-coupons-promo-consumer-app
  server:
    port: ${server-port:33000}
  metrics:
    binders:
      web:
        enabled: false # we are using our own binder via our custom micronaut-metrics lib

resilience4j:
  circuitbreaker:
    failure-rate-threshold: 50            # failure rate threshold in percentage (default: 50)
    wait-duration-secs-in-open-state: 10  # time cb waits before transitioning from open to half-open (default: 60s)
    sliding-window-type: TIME_BASED       # possible values TIME_BASED or COUNT_BASED (default: COUNT_BASED)
    sliding-window-size: 100               # seconds for TIME_BASED, request-count for COUNT_BASED (default: 100)
    minimum-number-of-calls: 10            # min calls required (per sliding window period) before cb calculates error rate (default: 10)
    permitted-number-of-calls-in-half-open-state: 10000  # min calls permitted when circuit breaker is half open

jdbc-stmt:
  serverStatementTimeoutMillis: 200  # for server side statement timeout
  statementQueryTimeoutSeconds: 1    # for client side statement timeout

jackson:
  property-naming-strategy: "SNAKE_CASE"

lists:
  metrics:
    binders:
      http:
        enabled: true # we are using our own binder via our custom micronaut-metrics lib

datasources:
  default:
    url: ${jdbc-url}
    driverClassName: org.postgresql.Driver
    username: ${dbuser}
    password: ${dbpassword}
    dialect: POSTGRES
    poolName: backpackregistrycouponsapp
    maximumPoolSize: 4        # default 10
    minimumIdle: 1            # default same as maximumPoolSize, valid if minimumIdle < maximumPoolSize
    idleTimeout: 600000       # default 600000ms (10min)
    maxLifetime: 1800000      # default 1800000ms (30min), should be shorter than any database imposed connection time limit
    connectionTimeout: 10000  # default: 30000ms (30 seconds)

flyway:
  schemas: lists
  datasources:
    default:
      locations: classpath:db.migration



filter:
  server:
    order:
      lists-brave-tracing-server-filter: 100
      list-authorization-filter: 200
  client:
    order:
      lists-brave-tracing-client-filter: 900
      metrics-filter: 850
      resilience-client-filter: 800
      oauth-filter: 701
      oauth-key-filter: 700

logging:
  mdc:
    enabled: true
    keys:
      - profile_id
      - x-api-id

api:
  oauth:
    url: https://oauth.iam.perf.target.com
    client-id: ${id2-client-id}
    client-secret: ${id2-client-secret}
    nuid-username: ${id2-nuid-username}
    nuid-password: ${id2-nuid-password}
    id2-refresh-mins: ${id2-refresh-minutes}

tracing:
  zipkin:
    enabled: false
    excluded-paths: /health
    b3-propagation-suppress: true
    sample-rate-percent: 0.5
    http:
      url: "https://zipkinserver.dev.target.com"
      messageMaxBytes: 50000
    app:
      name: backpackregistrycoupons
      env: stage
      region: tdc

api-key: ${api-key}

cart:
  client:
    refresh-cycle-sec: 999999999
    fastly-header-name: cartslb
    gcp-lb-header: eggo_grapenuts

components:
  server:
    list-authorization-filter:
      enabled: false
    sanitizing-filter:
      enabled: false

list:
  list-type: COUPONS
  max-count: 50
  max-pending-item-count: 100
  max-completed-items-count: 100
  abandon-after-duration-in-days: 730 # It is two years duration
  redsky-batch-size: 28

kafka:
  bootstrap:
    servers: ${kafka-vip}
#  ssl:
#    endpoint.identification.algorithm: ""# disable karka broker cert's hostname verification
#    keystore:
#      location: ${kafka-ssl-location}/client-keystore.jks
#      password: ${kafka-ssl-keypass}
#    truststore:
#      location: ${kafka-ssl-location}/client-truststore.jks
#      password: ${kafka-ssl-trustpass}
#      type: PKCS12
#  security:
#    protocol: ssl
  consumers:
    backpack-registry-coupons-msg-bus-consumer:
      key:
        deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value:
        deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
    backpack-registry-coupons-dlq-consumer:
      key:
        deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value:
        deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
    promo-msg-consumer:
      key:
        deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value:
        deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer

  producers:
    # default is a Jackson based JSON serializer for key/value
    lists-msg-bus-producer:
      retries: 3
      retry:
        backoff:
          ms: 1000
      max:
        in:
          flight:
            requests:
              per:
                connection: 1
        block:
          ms: 2000

msgbus:
  source: backpack-registry-coupons
  dlq-source: backpack-registry-coupons-dlq
  kafka:
    consumer:
      enabled: true
    producer:
      enabled: true
    dlqconsumer:
      enabled: true
    dlqproducer:
      enabled: true
    topic: ${kafka-msgbus-topic}
    consumer-group: backpack-registry-coupons-msg-bus-consumer
    consumer-batch-size: 10
    dlq-topic: ${kafka-dlq-topic}
    dlq-consumer-group: backpack-registry-coupons-dlq-consumer
    dlq-event-retry-interval-secs: 1
    dlq-max-event-retry-count: 2
    dlq-consumer-batch-size: 10

promo:
  source: promo
  kafka:
    consumer:
      client-id: backpack-promo-generic-consumer
      topic: ${kafka-promo-msgbus-topic}
      metrics-name: promo-producer
      consumer-group: promo-msg-consumer-dev
      default-event-type: promo-update-event
      consumer-batch-size: 10
      max-count-down-latch-wait-time: 10 # in seconds

endpoints:
  health:
    enabled: true
    sensitive: false

