micronaut:
  application:
    name: backpack-registry-coupons-consumer
  server:
    host: ${backpack-registry-coupons-consumer-host:localhost}
    port: 8085
  http:
    client.connect-ttl: 30m
    client.pool.acquire-timeout: 2000ms
    services:
      backpack-registry-api:
        urls:
          - "https://backpackregistry.dev.target.com"
        connect-timeout: 500ms
        read-timeout: 1000ms
        pool:
          enabled: true
  metrics:
    binders:
      web:
        enabled: false # we are using our own binder via our custom micronaut-metrics lib

filter:
  server:
    order:
      lists-brave-tracing-server-filter: 100
      list-authorization-filter: 200
      registry-channel-subchannel-filter: 400
  client:
    order:
      lists-brave-tracing-client-filter: 900
      resilience-client-filter: 800
      oauth-filter: 701
      oauth-key-filter: 700

components:
  server:
    list-authorization-filter:
      enabled: false
    sanitizing-filter:
      enabled: false
    registry-channel-subchannel-filter:
      enabled: false

msgbus:
  source: backpack-registry-coupons-consumer-app
  dlq-source: backpack-registry-coupons-consumer-app-dlq
  kafka:
    consumer:
      enabled: true
    producer:
      enabled: true
      client-id: backpack-registry-coupons-consumer-data-bus-dev-producer
    dlqconsumer:
      enabled: true
    dlqproducer:
      enabled: true
      client-id: backpack-registry-coupons-consumer-data-bus-dev-producer
    topic: registry-internal-data-bus-dev
    consumer-group: backpack-registry-coupons-bus-dev-consumer
    consumer-batch-size: 10
    dlq-topic: registry-internal-data-bus-dev-dlq
    dlq-consumer-group: backpack-registry-coupons-bus-dev-dlq-consumer
    dlq-event-retry-interval-secs: 1
    dlq-max-event-retry-count: 2
    dlq-consumer-batch-size: 10

notification:
  source: backpack-registry-coupons-consumer-app
  dlq-source: backpack-registry-coupons-consumer-app-dlq
  enabled: true


beacon:
  client:
    enabled: true
    source: backpack-registry-coupons-consumer-app
    dlq-source: backpack-registry-coupons-consumer-app-dlq
    kafka:
      consumer:
        client-id: backpack-registry-coupons-consumer-app-cron-beacon-consumer
        topic: registry-internal-data-bus-dev
        metrics-name: backpack-registry-coupons-consumer-app-cron-beacon-metrics
        consumer-group: backpack-registry-coupons-consumer-app-cron-beacon
        consumer-batch-size: 1
        max-count-down-latch-wait-time: 240 # in secondsConsumerRecord

kafka-sources:
  allow:
    - backpack-registry-coupons-consumer-app
    - backpack-registry-coupons-consumer-app-dlq
    - cronbeacon
    - cronbeacon-dlq
    - backpack-registry
    - backpack-registry-dlq
    - backpackregistry-migration

kafka:
  bootstrap:
    servers: kafka-ttc-app.dev.target.com:9093
  ssl:
    endpoint.identification.algorithm: ""# disable karka broker cert's hostname verification
    keystore:
      location: /lists-bus-keystore.jks
      password: ${kafka-secret.keystore-password}
    truststore:
      location: /client-truststore.jks
      password: ${kafka-secret.truststore-password}
      type: PKCS12
  security:
    protocol: ssl
  consumers:
    backpack-registry-coupons-bus-dev-consumer:
      key:
        deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value:
        deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
    backpack-registry-coupons-bus-dev-dlq-consumer:
      key:
        deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value:
        deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
    backpack-registry-coupons-consumer-app-cron-beacon:
      key:
        deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value:
        deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
  producers:
    # default is a Jackson based JSON serializer for key/value
    backpack-registry-coupons-bus-dev-producer:
      retries: 3
      retry:
        backoff:
          ms: 1000
      max:
        in:
          flight:
            requests:
              per:
                connection: 1
        block:
          ms: 2000
    notification-tracer-producer:
      retries: 3
      retry:
        backoff:
          ms: 1000
      max:
        in:
          flight:
            requests:
              per:
                connection: 1
        block:
          ms: 2000

postgres:
  max-db-pool-size: 5
  min-db-pool-size: 1
